from langchain.tools import BaseTool
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from config import OPENAI_API_KEY, LLM_MODEL
from constants import SUPPORT_HISTORY_LIMIT
from typing import Optional, Type
from pydantic import BaseModel, Field

class SupportInput(BaseModel):
    """Input for support tool."""
    issue_description: str = Field(description="ÙˆØµÙ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø£Ùˆ Ù…Ø´ÙƒÙ„Ø© Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡")

class SupportTool(BaseTool):
    """Tool for handling technical and customer support issues."""
    name: str = "support_tool"
    description: str = "Ù„Ø­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆÙ…Ø´Ø§ÙƒÙ„ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØ­ØªØ§Ø¬ ØªØ¯Ø®Ù„ Ø¨Ø´Ø±ÙŠ"
    args_schema: Type[BaseModel] = SupportInput

    def __init__(self, memory: ConversationBufferMemory):
        super().__init__()
        self._memory = memory
        self._llm = ChatOpenAI(model=LLM_MODEL, temperature=0.3, api_key=OPENAI_API_KEY)

        self._prompt = PromptTemplate(
            input_variables=["query", "chat_history"],
            template="""
# Ø¯ÙˆØ±Ùƒ
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¯Ø¹Ù… Ø¹Ù…Ù„Ø§Ø¡ Ù…ØªØ®ØµØµ ÙÙŠ Ø´Ø±ÙƒØ© Ø§ØªØµØ§Ù„Ø§Øª.

# Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©

## ðŸ• Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©:
{chat_history}

## ðŸ†• Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:
{query}

# Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ¹Ø§Ù…Ù„

## 1ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
Ø­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:
- ðŸ“¶ Ø´Ø¨ÙƒØ© Ø£Ùˆ ØªØºØ·ÙŠØ©
- ðŸ’³ ÙÙˆØªØ±Ø© Ø£Ùˆ Ø±ØµÙŠØ¯
- ðŸŒ Ø¥Ù†ØªØ±Ù†Øª Ø£Ùˆ Ø¨ÙŠØ§Ù†Ø§Øª
- ðŸ“ž Ù…ÙƒØ§Ù„Ù…Ø§Øª
- ðŸ”§ Ø¬Ù‡Ø§Ø² Ø£Ùˆ SIM
- ðŸ“‹ Ø¥Ø¯Ø§Ø±ÙŠ (ØªÙØ¹ÙŠÙ„/Ø¥Ù„ØºØ§Ø¡ Ø®Ø¯Ù…Ø©)

## 2ï¸âƒ£ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© (Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†)
Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¨Ø³ÙŠØ·Ø© ÙˆÙ„Ù‡Ø§ Ø­Ù„ Ù…Ø¹Ø±ÙˆÙ:

ðŸ”§ **Ø§Ù„Ø­Ù„:**

**Ø§Ù„Ø®Ø·ÙˆØ§Øª:**
1. [Ø®Ø·ÙˆØ© 1]
2. [Ø®Ø·ÙˆØ© 2]
3. [Ø®Ø·ÙˆØ© 3]

âœ… Ù‡Ø°Ø§ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©. Ø¬Ø±Ù‘Ø¨ ÙˆØ£Ø®Ø¨Ø±Ù†ÙŠ Ø¥Ø°Ø§ Ø§Ø³ØªÙ…Ø±Øª.

## 3ï¸âƒ£ Ø§Ù„ØªØµØ¹ÙŠØ¯ (Escalation)
Ø¥Ø°Ø§ Ø§Ø­ØªØ§Ø¬Øª ØªØ¯Ø®Ù„ Ø¨Ø´Ø±ÙŠ:

ðŸ™‹ **Ø³Ø£Ø­ÙˆÙ„Ùƒ Ù„Ù„Ø¯Ø¹Ù… Ø§Ù„Ù…ØªØ®ØµØµ**

**Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„:**
ðŸ“ž Ø±Ù‚Ù… Ø§Ù„Ø¯Ø¹Ù…: Ù¡Ù¦Ù 
ðŸ• Ù…ØªØ§Ø­: Ù¢Ù¤/Ù§
ðŸ’¬ Ø§Ù„Ø´Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±: Ù…ØªØ§Ø­ Ø¹Ø¨Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚

**Ù‚Ø¨Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ØŒ Ø¬Ù‡Ù‘Ø²:**
â€¢ Ø±Ù‚Ù… Ø®Ø·Ùƒ
â€¢ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
â€¢ Ø£ÙŠ Ø±Ø³Ø§Ø¦Ù„ Ø®Ø·Ø£ Ø¸Ù‡Ø±Øª Ù„Ùƒ

âœ… Ø³ÙŠØªÙ… Ø­Ù„ Ù…Ø´ÙƒÙ„ØªÙƒ Ø¨Ø³Ø±Ø¹Ø©.

## 4ï¸âƒ£ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©
Ø§Ø³Ø£Ù„ Ø¯Ø§Ø¦Ù…Ø§Ù‹ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©:
"Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø´ÙŠØ¡ Ø¢Ø®Ø± ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ù‡ØŸ ðŸ˜Š"

# Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø±Ø¯
- ØªØ¹Ø§Ø·Ù Ù…Ø¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
- Ù‚Ø¯Ù… Ø­Ù„ Ø³Ø±ÙŠØ¹ Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†
- Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ Ø§Ù„ØªØµØ¹ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù…Ø¹Ù‚Ø¯Ø©
- Ù„Ø§ ØªØ·ÙŠÙ„ Ø§Ù„Ø±Ø¯ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¹Ù (100-150 ÙƒÙ„Ù…Ø© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰)

# Ù†Ø¨Ø±Ø© Ø§Ù„Ø±Ø¯
- Ù…ØªÙÙ‡Ù…: "Ø£ØªÙÙ‡Ù… Ø£Ù† Ù‡Ø°Ø§ Ù…Ø²Ø¹Ø¬ØŒ Ø¯Ø¹Ù†ÙŠ Ø£Ø³Ø§Ø¹Ø¯Ùƒ..."
- Ø¥ÙŠØ¬Ø§Ø¨ÙŠ: "Ø³Ù†Ø­Ù„ Ù‡Ø°Ø§ Ù…Ø¹Ø§Ù‹!"
- Ù…Ù‡Ù†ÙŠ: Ø¹Ø¯Ù… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„ØºØ© Ø¹Ø§Ù…ÙŠØ© ØºÙŠØ± Ù„Ø§Ø¦Ù‚Ø©

Ø§Ù„Ø±Ø¯:
"""
        )
        self._chain = LLMChain(llm=self._llm, prompt=self._prompt)

    def _run(self, issue_description: str, session_id: Optional[str] = None) -> str:
        """Run the support tool."""
        # Get chat history from the agent's memory
        chat_history = ""
        if self._memory and hasattr(self._memory, 'chat_memory'):
            messages = self._memory.chat_memory.messages
            recent_messages = messages[-SUPPORT_HISTORY_LIMIT:] if len(messages) > SUPPORT_HISTORY_LIMIT else messages
            chat_history = "\n".join([
                f"{'User' if hasattr(msg, 'content') and 'Human' in str(type(msg)) else 'Assistant'}: {msg.content}" 
                for msg in recent_messages if hasattr(msg, 'content')
            ])

        response = self._chain.run(
            query=issue_description,
            chat_history=chat_history
        )

        return response

    async def _arun(self, issue_description: str, session_id: Optional[str] = None) -> str:
        """Async run method."""
        return self._run(issue_description, session_id)
